# app.py
import os
import re
import pickle
from collections import Counter

import numpy as np
import pandas as pd
import streamlit as st
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from wordcloud import WordCloud

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_H5       = "best_lstm.h5"
TOKENIZER_PKL  = "tokenizer.pkl"
CSV_LABELED    = r"D:\_DeepNLP25\site\cache\reviews_labeled.csv"
MAX_LEN        = 100
FONT_PATH      = "C:/Windows/Fonts/malgun.ttf"
LABEL_MAP      = {0: "ë¶€ì •", 1: "ì¤‘ë¦½", 2: "ê¸ì •"}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ëª¨ë¸Â·í† í¬ë‚˜ì´ì €Â·ì›ë³¸ ë°ì´í„° ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model     = load_model(MODEL_H5)
tokenizer = pickle.load(open(TOKENIZER_PKL, "rb"))

df = pd.read_csv(CSV_LABELED, encoding="utf-8-sig", low_memory=False)
if df["label"].dtype == object:
    df["label"] = df["label"].map({"ë¶€ì •":0, "ì¤‘ë¦½":1, "ê¸ì •":2})
df = df.dropna(subset=["review","label"]).reset_index(drop=True)
df["label"] = df["label"].astype(int)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ì „ì²˜ë¦¬ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clean_text(s: str) -> str:
    s = re.sub(r"[^ã„±-ã…ã…-ã…£ê°€-í£A-Za-z0-9 ]", "", str(s))
    return s.lower().strip()

df["clean"] = df["review"].map(clean_text)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ì „ì²´ ë°ì´í„° ë°°ì¹˜ ì˜ˆì¸¡ (verbose=0 ìœ¼ë¡œ ë©”ì‹œì§€ ìˆ¨ê¹€)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
seqs  = tokenizer.texts_to_sequences(df["clean"])
pads  = pad_sequences(seqs, maxlen=MAX_LEN, padding="post")
probs = model.predict(pads, verbose=0)
df["pred"] = np.argmax(probs, axis=1)
df["confidence"] = np.max(probs, axis=1)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) Streamlit UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ë¦¬ë·° ê°ì„± ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸ“Š ë¦¬ë·° ê°ì„± ë¶„ì„ & í”¼ë“œë°± (ì›ë³¸ CSV ì§ì ‘ ìˆ˜ì •)")

# 4.1) ë¦¬ë·° ì…ë ¥ & ì˜ˆì¸¡
st.header("ğŸ“© ë¦¬ë·° ì…ë ¥ & ì˜ˆì¸¡")
user_review = st.text_area("ë¶„ì„í•  ë¦¬ë·°ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", height=150)

if st.button("ì˜ˆì¸¡í•˜ê¸°"):
    # ì˜ˆì¸¡
    seq  = tokenizer.texts_to_sequences([clean_text(user_review)])
    pad  = pad_sequences(seq, maxlen=MAX_LEN, padding="post")
    prob = model.predict(pad, verbose=0)[0]
    pred = int(np.argmax(prob))
    conf = float(np.max(prob))
    st.write(f"ğŸ” ì˜ˆì¸¡ ê²°ê³¼: **{LABEL_MAP[pred]}**  (ì‹ ë¢°ë„: {conf:.2f})")

    # í”¼ë“œë°± ë°›ê¸°
    st.write("### í˜¹ì‹œ ë¶„ë¥˜ê°€ ì˜ëª»ë˜ì—ˆë‚˜ìš”?")
    correct = st.radio(
        "ì˜¬ë°”ë¥¸ ë¼ë²¨ì„ ì„ íƒí•˜ì„¸ìš”.",
        options=[0,1,2],
        format_func=lambda x: LABEL_MAP[x]
    )

    if st.button("âœ… í”¼ë“œë°± ì €ì¥ (ì›ë³¸ CSV ì—…ë°ì´íŠ¸)"):
        # 1) ë©”ëª¨ë¦¬ìƒì˜ dfì—ë„ ë°˜ì˜
        mask = df["review"] == user_review
        if mask.any():
            df.loc[mask, "label"] = correct
            df.loc[mask, "pred"]  = correct
            # 2) ë°”ë¡œ ì›ë³¸ CSVì— ë®ì–´ì“°ê¸°
            df.to_csv(CSV_LABELED, index=False, encoding="utf-8-sig")
            st.success("ì›ë³¸ reviews_labeled.csvê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.error("í•´ë‹¹ ë¦¬ë·°ê°€ ì›ë³¸ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤â€”ì—…ë°ì´íŠ¸ ì‹¤íŒ¨.")

# 4.2) ì „ì²´ ì •í™•ë„
accuracy = (df["pred"] == df["label"]).mean()
st.markdown(f"**ì „ì²´ ë°ì´í„° ì •í™•ë„:** {accuracy:.3f}")

# 4.3) ì˜ˆì¸¡ ë¼ë²¨ ë¶„í¬
st.subheader("ì˜ˆì¸¡ ë¼ë²¨ ë¶„í¬")
dist = pd.Series(df["pred"]).map(LABEL_MAP).value_counts()
st.bar_chart(dist)

# 4.4) ê°ì •ë³„ ì›Œë“œí´ë¼ìš°ë“œ
st.subheader("ê°ì •ë³„ ì›Œë“œí´ë¼ìš°ë“œ")
cols = st.columns(3)
for i, name in LABEL_MAP.items():
    texts = " ".join(df[df["pred"]==i]["clean"])
    if not texts:
        cols[i].write(f"{name} ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        wc = WordCloud(
            font_path=FONT_PATH,
            width=400, height=200,
            background_color="white"
        ).generate(texts)
        cols[i].image(wc.to_array(), caption=name, use_container_width=True)

# 4.5) ê°ì •ë³„ ìƒìœ„ 20ë‹¨ì–´ ë¹ˆë„
st.subheader("ê°ì •ë³„ ìƒìœ„ 20ë‹¨ì–´ ë¹ˆë„")
for i, name in LABEL_MAP.items():
    tokens  = [tok for txt in df[df["pred"]==i]["clean"] for tok in txt.split()]
    counter = Counter(tokens)
    top20   = counter.most_common(20)
    if not top20:
        st.markdown(f"**{name} ë¦¬ë·°ì— ë‹¨ì–´ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**")
    else:
        words, counts = zip(*top20)
        st.markdown(f"**{name} Top 20 ë‹¨ì–´**")
        st.bar_chart(pd.Series(counts, index=words))
